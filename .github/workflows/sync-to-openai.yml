name: Sync Repo to OpenAI Storage (per-file)

on:
  workflow_call:
    inputs:
      vector_store_id:
        required: true
        type: string
    secrets:
      OPENAI_API_KEY:
        required: true

jobs:
  sync-repo:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
        with:
          fetch-depth: 0

      - uses: actions/setup-node@v4
        with:
          node-version: 20

      - run: npm i openai@^4

      - name: Upload files one by one
        run: |
          node --input-type=module - <<'NODE'
          import fs from "fs";
          import path from "path";
          import { execSync } from "child_process";
          import OpenAI from "openai";

          const apiKey   = process.env.OPENAI_API_KEY;
          const vsId     = process.env.VECTOR_STORE_ID;
          const repoName = (process.env.GITHUB_REPOSITORY || "").split("/").pop();

          if (!apiKey) throw new Error("Missing OPENAI_API_KEY");
          if (!vsId)   throw new Error("Missing VECTOR_STORE_ID");

          const client = new OpenAI({ apiKey });

          // collect repo files
          const allFiles = execSync("git ls-files", { encoding: "utf-8" })
            .split("\n")
            .filter(f =>
              f &&
              !f.startsWith(".git/") &&
              !f.startsWith(".github/workflows/") &&
              !f.includes("node_modules") &&
              !/\.(png|jpg|jpeg|gif|svg|ico|lock)$/i.test(f)
            );

          console.log(`Found ${allFiles.length} candidate files`);

          (async () => {
            for (const relPath of allFiles) {
              const absPath = path.resolve(relPath);
              if (!fs.existsSync(absPath)) continue;
              const stat = fs.statSync(absPath);
              if (!stat.isFile() || stat.size > 2 * 1024 * 1024) {
                console.log(`Skipping ${relPath} (too large or not a file)`);
                continue;
              }

              const vectorName = `${repoName}/${relPath}`;
              console.log(`Processing ${vectorName} (${stat.size} bytes)`);

              // delete any old version
              const list0 = await client.vectorStores.files.list(vsId);
              const olds  = list0.data.filter(f => f.filename === vectorName);
              for (const old of olds) {
                console.log(`Deleting old: ${old.filename}`);
                await client.vectorStores.files.del(vsId, old.id);
              }

              try {
                let vf;
                if (typeof client.vectorStores?.files?.uploadAndPoll === "function") {
                  vf = await client.vectorStores.files.uploadAndPoll(
                    vsId,
                    fs.createReadStream(absPath),
                    { filename: vectorName }
                  );
                } else {
                  const created = await client.files.create({
                    file: fs.createReadStream(absPath),
                    purpose: "assistants"
                  });
                  vf = await client.vectorStores.files.createAndPoll(vsId, {
                    file_id: created.id
                  });
                }

                console.log(`Indexed: ${vf.filename} (status: ${vf.status})`);
              } catch (err) {
                const body = err?.response?.data || err?.stack || err?.message || err;
                console.error(`‚ùå Failed ${vectorName}:`, body);
              }
            }
          })();
          NODE
        env:
          OPENAI_API_KEY: ${{ secrets.OPENAI_API_KEY }}
          VECTOR_STORE_ID: ${{ inputs.vector_store_id }}
